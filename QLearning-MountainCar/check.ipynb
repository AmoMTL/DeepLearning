{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "236830c0-ca94-4875-9ec9-fe2959e205c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.5844998,  0.       ], dtype=float32), {})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make(\"MountainCar-v0\", render_mode=None)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fed3278a-3c36-4ce3-a889-820cd503fede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.goal_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd2db357-9729-4b87-b2ab-dc0721a94dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6 , 0.07], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7030a192-f03d-45c5-9f63-b29bff33b94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.low[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "305bcedb-b6eb-4553-b87e-98be60a24451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets_size = 40\n",
    "discreet_os_size = [buckets_size] * len(env.observation_space.high)\n",
    "discreet_os_win_size = (env.observation_space.high - env.observation_space.low) / discreet_os_size\n",
    "\n",
    "obj_end_discreet_state = ((env.goal_position - env.observation_space.low[0]) / discreet_os_win_size[0]).astype(int)\n",
    "obj_end_discreet_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e889b63e-2ae3-4f3f-9a53-f6da1f7d2aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discreet_state(state):\n",
    "    discreet_state = (state - env.observation_space.low) / discreet_os_win_size\n",
    "    return tuple(discreet_state.astype(int))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e84ffe81-0122-44cf-a1e4-d3e3a386d41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "start_discreet = get_discreet_state(state[0])\n",
    "start_discreet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a01383-7cfb-4915-84b0-8fc6bdda2f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ce40a9-5b6d-4d7c-a50a-de8502541383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a685e6f-5741-4281-9564-7421180013c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22fff966-5ae9-4e4e-83f9-0e663dddd844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc2210d-f329-4f26-8844-e23afb7a4735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 20]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets_size = 20\n",
    "obs_size = [buckets_size] * len(env.observation_space.high)\n",
    "obs_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dde493b5-c1e2-4a13-9381-6da8c77606de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09 , 0.007])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discreet_os_win_size = (env.observation_space.high - env.observation_space.low) / obs_size\n",
    "discreet_os_win_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1263034e-dd6c-4ac9-aa09-5d606610818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discreet_state(state):\n",
    "    discreet_state = (state - env.observation_space.low) / discreet_os_win_size\n",
    "    return tuple(discreet_state.astype(int))\n",
    "\n",
    "epsilon = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "212edd84-e20c-40c6-8249-ee7668232bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 200000\n",
    "render_per = 1000\n",
    "\n",
    "learning_rate = 0.1\n",
    "discount = 0.95 # how important we find future actions\n",
    "\n",
    "epsilon = 0.95\n",
    "decay_from = 1000\n",
    "\n",
    "buckets_size = 20\n",
    "discreet_os_size = [buckets_size] * len(env.observation_space.high)\n",
    "discreet_os_win_size = (env.observation_space.high - env.observation_space.low) / discreet_os_size\n",
    "q_table = np.random.uniform(low=-2, high=0, size=(discreet_os_size + [env.action_space.n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3876ffeb-2591-4423-8877-c35ad6cbc02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 Reward:-200.0\n",
      "Episode: 1000 Reward:-200.0\n",
      "Episode: 2000 Reward:-200.0\n",
      "Episode: 3000 Reward:-200.0\n",
      "Episode: 4000 Reward:-200.0\n",
      "Episode: 5000 Reward:-200.0\n",
      "Episode: 6000 Reward:-200.0\n",
      "Episode: 7000 Reward:-200.0\n",
      "Episode: 8000 Reward:-200.0\n",
      "Episode: 9000 Reward:-200.0\n",
      "Episode: 10000 Reward:-200.0\n",
      "Episode: 11000 Reward:-200.0\n",
      "Episode: 12000 Reward:-200.0\n",
      "Episode: 13000 Reward:-200.0\n",
      "Episode: 14000 Reward:-200.0\n",
      "Episode: 15000 Reward:-200.0\n",
      "Episode: 16000 Reward:-200.0\n",
      "Episode: 17000 Reward:-200.0\n",
      "Episode: 18000 Reward:-200.0\n",
      "Episode: 19000 Reward:-200.0\n",
      "Episode: 20000 Reward:-200.0\n",
      "Episode: 21000 Reward:-200.0\n",
      "Episode: 22000 Reward:-200.0\n",
      "Episode: 23000 Reward:-200.0\n",
      "Episode: 24000 Reward:-200.0\n",
      "Episode: 25000 Reward:-200.0\n",
      "Episode: 26000 Reward:-200.0\n",
      "Episode: 27000 Reward:-200.0\n",
      "Episode: 28000 Reward:-200.0\n",
      "Episode: 29000 Reward:-200.0\n",
      "Episode: 30000 Reward:-200.0\n",
      "Episode: 31000 Reward:-200.0\n",
      "Episode: 32000 Reward:-200.0\n",
      "Episode: 33000 Reward:-200.0\n",
      "Episode: 34000 Reward:-200.0\n",
      "Episode: 35000 Reward:-200.0\n",
      "Episode: 36000 Reward:-200.0\n",
      "Episode: 37000 Reward:-200.0\n",
      "Episode: 38000 Reward:-200.0\n",
      "Episode: 39000 Reward:-200.0\n",
      "Episode: 40000 Reward:-200.0\n",
      "Episode: 41000 Reward:-200.0\n",
      "Episode: 42000 Reward:-200.0\n",
      "Episode: 43000 Reward:-200.0\n",
      "Episode: 44000 Reward:-200.0\n",
      "Episode: 45000 Reward:-200.0\n",
      "Episode: 46000 Reward:-200.0\n",
      "Episode: 47000 Reward:-200.0\n",
      "Episode: 48000 Reward:-200.0\n",
      "Episode: 49000 Reward:-200.0\n",
      "Episode: 50000 Reward:-200.0\n",
      "Episode: 51000 Reward:-200.0\n",
      "Episode: 52000 Reward:-200.0\n",
      "Episode: 53000 Reward:-200.0\n",
      "Episode: 54000 Reward:-200.0\n",
      "Episode: 55000 Reward:-200.0\n",
      "Episode: 56000 Reward:-200.0\n",
      "Episode: 57000 Reward:-200.0\n",
      "Episode: 58000 Reward:-200.0\n",
      "Episode: 59000 Reward:-200.0\n",
      "Episode: 60000 Reward:-200.0\n",
      "Episode: 61000 Reward:-200.0\n",
      "Episode: 62000 Reward:-200.0\n",
      "Episode: 63000 Reward:-200.0\n",
      "Episode: 64000 Reward:-200.0\n",
      "Episode: 65000 Reward:-200.0\n",
      "Episode: 66000 Reward:-200.0\n",
      "Episode: 67000 Reward:-200.0\n",
      "Episode: 68000 Reward:-200.0\n",
      "Episode: 69000 Reward:-200.0\n",
      "Episode: 70000 Reward:-200.0\n",
      "Episode: 71000 Reward:-200.0\n",
      "Episode: 72000 Reward:-200.0\n",
      "Episode: 73000 Reward:-200.0\n",
      "Episode: 74000 Reward:-200.0\n",
      "Episode: 75000 Reward:-200.0\n",
      "Episode: 76000 Reward:-200.0\n",
      "Episode: 77000 Reward:-200.0\n",
      "Episode: 78000 Reward:-200.0\n",
      "Episode: 79000 Reward:-200.0\n",
      "Episode: 80000 Reward:-200.0\n",
      "Episode: 81000 Reward:-200.0\n",
      "Episode: 82000 Reward:-200.0\n",
      "Episode: 83000 Reward:-200.0\n",
      "Episode: 84000 Reward:-200.0\n",
      "Episode: 85000 Reward:-200.0\n",
      "Episode: 86000 Reward:-200.0\n",
      "Episode: 87000 Reward:-200.0\n",
      "Episode: 88000 Reward:-200.0\n",
      "Episode: 89000 Reward:-200.0\n",
      "Episode: 90000 Reward:-200.0\n",
      "Episode: 91000 Reward:-200.0\n",
      "Episode: 92000 Reward:-200.0\n",
      "Episode: 93000 Reward:-200.0\n",
      "Episode: 94000 Reward:-200.0\n",
      "Episode: 95000 Reward:-200.0\n",
      "Episode: 96000 Reward:-200.0\n",
      "Episode: 97000 Reward:-200.0\n",
      "Episode: 98000 Reward:-200.0\n",
      "Episode: 99000 Reward:-200.0\n",
      "Episode: 100000 Reward:-200.0\n",
      "Episode: 101000 Reward:-200.0\n",
      "Episode: 102000 Reward:-200.0\n",
      "Episode: 103000 Reward:-200.0\n",
      "Episode: 104000 Reward:-200.0\n",
      "Episode: 105000 Reward:-200.0\n",
      "Episode: 106000 Reward:-200.0\n",
      "Episode: 107000 Reward:-200.0\n",
      "Episode: 108000 Reward:-200.0\n",
      "Episode: 109000 Reward:-200.0\n",
      "Episode: 110000 Reward:-200.0\n",
      "Episode: 111000 Reward:-200.0\n",
      "Episode: 112000 Reward:-200.0\n",
      "Episode: 113000 Reward:-200.0\n",
      "Episode: 114000 Reward:-200.0\n",
      "Episode: 115000 Reward:-200.0\n",
      "Episode: 116000 Reward:-200.0\n",
      "Episode: 117000 Reward:-200.0\n",
      "Episode: 118000 Reward:-200.0\n",
      "Episode: 119000 Reward:-200.0\n",
      "Episode: 120000 Reward:-200.0\n",
      "Episode: 121000 Reward:-200.0\n",
      "Episode: 122000 Reward:-200.0\n",
      "Episode: 123000 Reward:-200.0\n",
      "Episode: 124000 Reward:-200.0\n",
      "Episode: 125000 Reward:-200.0\n",
      "Episode: 126000 Reward:-200.0\n",
      "Episode: 127000 Reward:-200.0\n",
      "Episode: 128000 Reward:-200.0\n",
      "Episode: 129000 Reward:-200.0\n",
      "Episode: 130000 Reward:-200.0\n",
      "Episode: 131000 Reward:-200.0\n",
      "Episode: 132000 Reward:-200.0\n",
      "Episode: 133000 Reward:-200.0\n",
      "Episode: 134000 Reward:-200.0\n",
      "Episode: 135000 Reward:-200.0\n",
      "Episode: 136000 Reward:-200.0\n",
      "Episode: 137000 Reward:-200.0\n",
      "Episode: 138000 Reward:-200.0\n",
      "Episode: 139000 Reward:-200.0\n",
      "Episode: 140000 Reward:-200.0\n",
      "Episode: 141000 Reward:-200.0\n",
      "Episode: 142000 Reward:-200.0\n",
      "Episode: 143000 Reward:-200.0\n",
      "Episode: 144000 Reward:-200.0\n",
      "Episode: 145000 Reward:-200.0\n",
      "Episode: 146000 Reward:-200.0\n",
      "Episode: 147000 Reward:-200.0\n",
      "Episode: 148000 Reward:-200.0\n",
      "Episode: 149000 Reward:-200.0\n",
      "Episode: 150000 Reward:-200.0\n",
      "Episode: 151000 Reward:-200.0\n",
      "Episode: 152000 Reward:-200.0\n",
      "Episode: 153000 Reward:-200.0\n",
      "Episode: 154000 Reward:-200.0\n",
      "Episode: 155000 Reward:-200.0\n",
      "Episode: 156000 Reward:-200.0\n",
      "Episode: 157000 Reward:-200.0\n",
      "Episode: 158000 Reward:-200.0\n",
      "Episode: 159000 Reward:-200.0\n",
      "Episode: 160000 Reward:-200.0\n",
      "Episode: 161000 Reward:-200.0\n",
      "Episode: 162000 Reward:-200.0\n",
      "Episode: 163000 Reward:-200.0\n",
      "Episode: 164000 Reward:-200.0\n",
      "Episode: 165000 Reward:-200.0\n",
      "Episode: 166000 Reward:-200.0\n",
      "Episode: 167000 Reward:-200.0\n",
      "Episode: 168000 Reward:-200.0\n",
      "Episode: 169000 Reward:-200.0\n",
      "Episode: 170000 Reward:-200.0\n",
      "Episode: 171000 Reward:-200.0\n",
      "Episode: 172000 Reward:-200.0\n",
      "Episode: 173000 Reward:-200.0\n",
      "Episode: 174000 Reward:-200.0\n",
      "Episode: 175000 Reward:-200.0\n",
      "Episode: 176000 Reward:-200.0\n",
      "Episode: 177000 Reward:-200.0\n",
      "Episode: 178000 Reward:-200.0\n",
      "Episode: 179000 Reward:-200.0\n",
      "Episode: 180000 Reward:-200.0\n",
      "Episode: 181000 Reward:-200.0\n",
      "Episode: 182000 Reward:-200.0\n",
      "Episode: 183000 Reward:-200.0\n",
      "Episode: 184000 Reward:-200.0\n",
      "Episode: 185000 Reward:-200.0\n",
      "Episode: 186000 Reward:-200.0\n",
      "Episode: 187000 Reward:-200.0\n",
      "Episode: 188000 Reward:-200.0\n",
      "Episode: 189000 Reward:-200.0\n",
      "Episode: 190000 Reward:-200.0\n",
      "Episode: 191000 Reward:-200.0\n",
      "Episode: 192000 Reward:-200.0\n",
      "Episode: 193000 Reward:-200.0\n",
      "Episode: 194000 Reward:-200.0\n",
      "Episode: 195000 Reward:-200.0\n",
      "Episode: 196000 Reward:-200.0\n",
      "Episode: 197000 Reward:-200.0\n",
      "Episode: 198000 Reward:-200.0\n",
      "Episode: 199000 Reward:-200.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "done = False\n",
    "\n",
    "rewards =[]\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    discreet_state = get_discreet_state(state[0])\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    while not done:    \n",
    "        #if np.random.random() > epsilon:\n",
    "        action = np.argmax(q_table[discreet_state])\n",
    "        #else:\n",
    "            #action = np.random.randint(0, env.action_space.n)\n",
    "            \n",
    "        new_state, reward, termination, truncation, _ = env.step(action)\n",
    "        done = termination or truncation\n",
    "        episode_reward += reward\n",
    "        new_discreet_state = get_discreet_state(new_state)\n",
    "        current_q = q_table[discreet_state + (action,)]    \n",
    "        if not done:\n",
    "            max_future_q = np.max(q_table[discreet_state + (action,)])\n",
    "            new_q = (1 - learning_rate) * current_q + learning_rate * (reward + discount * max_future_q)            \n",
    "            q_table[discreet_state, (action,)] = new_q\n",
    "            #print(new_q)\n",
    "        elif new_state[0] >= env.goal_position:\n",
    "            q_table[discreet_state + (action, )] = 0\n",
    "            print(f\"I made it on episode {episode}\")\n",
    "    \n",
    "        discreet_state = new_discreet_state\n",
    "\n",
    "    rewards.append(episode_reward)\n",
    "\n",
    "    if episode%render_per == 0:\n",
    "        print(f\"Episode: {episode} Reward:{episode_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "282baabc-0eb4-4d9a-aa0f-08f61c3c36f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.45797673,  0.        ], dtype=float32), {})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "609d5fb9-e2ec-4b59-a7d1-09e491497857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.goal_position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e23c8132-5138-4c87-a3dc-8049844fd19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6303953"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b33ccb6-6ff2-43d9-85d7-1d7c0c532143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, -70)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_discreet_state(new_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd99f5d5-5978-4c11-ad56-2129b8b9246b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.4152215 , 25.49277608])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discreet_state = (new_state - env.observation_space.low) / discreet_os_win_size\n",
    "discreet_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47b33537-88df-442d-bc6c-676bc811cdc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.626948  , 0.07137977], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state - env.observation_space.low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26b529a6-5cec-4a7d-b7e3-69a98ad8031b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.2 , -0.07], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4089311f-66e0-4864-adcc-b137b450c62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.481647  , -0.00550979], dtype=float32), -1.0, False, False, {})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb50b74-0489-4f5b-b468-e474dd2a5756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "learn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
